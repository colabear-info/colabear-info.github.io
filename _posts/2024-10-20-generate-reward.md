---
title: "Generative Verifiers: Reward Modeling as Next-Token Prediction"
last_modified_at: 2024-10-20T12:12:06-05:00
categories:
  - Blog
tags:
  - life
---

无代码，可以考虑复现，大概的思路是，
Generative Verifiers: Reward Modeling as Next-Token Prediction ，用cot的token的输出来当做reward，去训练网络。主要可以借鉴的是它所使用的dataset. 

一个做image token压缩的思路是和vq-vae结合。

multimodality的图片positional embedding可能不能直接用原有的rope，而是应该做一个调整。

又想整活AI 斯坦福小镇的一天。


人这一辈子很长，但时间又过的很快。（谷神）
